{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\n",
    "    'id': '主键',\n",
    "    'XINGBIE': '性别',\n",
    "    'CSNY': '出生年月',\n",
    "    'HYZK': '婚姻状况',\n",
    "    'ZHIYE': '职业',\n",
    "    'ZHICHEN': '职称',\n",
    "    'ZHIWU': '职务',\n",
    "    'XUELI': '学历',\n",
    "    'DWJJLX': '单位经济类型',\n",
    "    'DWSSHY': '单位所属行业',\n",
    "    'GRJCJS': '个人缴存基数',\n",
    "    'GRZHZT': '个人账户状态',\n",
    "    'GRZHYE': '个人账户余额',\n",
    "    'GRZHSNJZYE': '个人账户上年结转余额',\n",
    "    'GRZHDNGJYE': '个人账户当年归集余额', \n",
    "    'GRYJCE': '个人月缴存额',\n",
    "    'DWYJCE': '单位月缴存额',\n",
    "    'DKFFE': '贷款发放额',\n",
    "    'DKYE': '贷款余额',\n",
    "    'DKLL': '贷款利率',\n",
    "    'label': '是否逾期'\n",
    "}\n",
    "drop_cols = ['主键', '婚姻状况', '职业', '职称', '职务', '学历', '单位月缴存额', '是否逾期']\n",
    "raw_cate_cols = ['单位经济类型', '单位所属行业', '个人账户状态', '性别' ]\n",
    "raw_num_cols = ['个人缴存基数', '个人账户余额', '个人账户上年结转余额', '个人账户当年归集余额', '个人月缴存额', '贷款发放额', \n",
    "                '贷款余额', '贷款利率']\n",
    "root = '../data'\n",
    "dt = \"2021-1-01 00:00:00\"\n",
    "timestamp_assign = time.strptime(dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "timestamp_assign=time.mktime(timestamp_assign)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(root+'/train.csv')\n",
    "test = pd.read_csv(root+'/test.csv')\n",
    "submit = pd.read_csv(root+'/submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis = 0).reset_index(drop = True)\n",
    "df.columns=df.columns.map(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首套\n",
    "#5年以上3.25： 2.708\n",
    "#1-5年 2.75： 2.292\n",
    "#二套\n",
    "#5年以上 3.575： 2.979\n",
    "#1-5年 3.025： 2.521\n",
    "rate_dict = {3.025: 2.521, 3.575: 2.979, 3.25: 2.708, 2.75: 2.292}\n",
    "\n",
    "def rate_func(x):\n",
    "    if x == 3.025:\n",
    "        return 2.521\n",
    "    if x == 3.575:\n",
    "        return 2.979\n",
    "    if x == 3.25:\n",
    "        return 2.708\n",
    "    if x == 2.75:\n",
    "        return 2.292\n",
    "    return x\n",
    "\n",
    "def loan_years(x):\n",
    "    if x == 2.708 or x == 2.979:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def num_house(x):\n",
    "    if x == 2.521 or x== 2.979:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def monthly_house_payments(p, i):\n",
    "    if i == 2.708 or i == 2.979:\n",
    "        n = 30*12\n",
    "    else:\n",
    "        n = 5*12\n",
    "    i = i/100\n",
    "    return p*i*(1+i)**n/((1+i)**n-1)\n",
    "\n",
    "def ability_pay(gz, gjj, yg):\n",
    "    #还贷能力系数\n",
    "    return (gz+gjj)/yg\n",
    "\n",
    "def convert(x):\n",
    "    age = (datetime.datetime.fromtimestamp(timestamp_assign)-datetime.datetime.fromtimestamp(x)).days\n",
    "    return age//365+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_table(df):\n",
    "    df['出生年月'] = df['出生年月'].apply(convert)\n",
    "    df['贷款利率'] = df['贷款利率'].apply(rate_func)\n",
    "    df, genFeats1 = get_bin(df, col = '出生年月', bins=[18,25,30,35,40,45])\n",
    "    df, genFeats2 = get_bin(df, col = '贷款余额', bins=[100000, 120000, 140000, 180000, 220000, 260000, 300000])\n",
    "    df, genFeats3 = get_bin(df, col = '贷款发放额', bins=[100000, 120000, 140000, 180000, 220000, 260000, 300000])\n",
    "    df['贷款发放额_贷款余额'] = df['贷款发放额'] + df['贷款余额']\n",
    "    df['贷款发放额_贷款余额_multi_贷款利率'] = (df['贷款发放额'] + df['贷款余额']) * df['贷款利率']\n",
    "    df['贷款发放额_multi_贷款利率'] = df['贷款发放额'] * df['贷款利率']\n",
    "    df['贷款余额_multi_贷款利率'] = df['贷款余额'] * df['贷款利率']\n",
    "\n",
    "    df['贷款发放额_multi_贷款利率_ratio'] = df['贷款发放额'] * df['贷款利率'] / df['贷款发放额_贷款余额_multi_贷款利率']\n",
    "    df['贷款余额_multi_贷款利率_ratio'] = df['贷款余额'] * df['贷款利率'] / df['贷款发放额_贷款余额_multi_贷款利率']\n",
    "    df['贷款余额_贷款发放额_ratio'] = df['贷款余额'] / df['贷款发放额_贷款余额']\n",
    "    df['贷款发放额_贷款余额_ratio'] = df['贷款发放额'] / df['贷款发放额_贷款余额']\n",
    "    df['个人账户余额_diff_个人账户当年归集余额'] = df['个人账户余额'] - df['个人账户当年归集余额']\n",
    "    df['个人账户余额_diff_个人账户上年结转余额'] = df['个人账户余额'] - df['个人账户上年结转余额']\n",
    "    df['月供'] = df.apply(lambda row: monthly_house_payments(row['贷款发放额'], row['贷款利率']), axis=1)\n",
    "    df['月供2'] = df.apply(lambda row: monthly_house_payments(row['贷款余额'], row['贷款利率']), axis=1)\n",
    "    df['还贷能力系数'] = df.apply(lambda row: ability_pay(row['个人缴存基数'], row['个人月缴存额'], row['月供']), axis=1)\n",
    "    df['月供/个人缴存基数'] = df['月供']/df['个人缴存基数']\n",
    "    df['月供/个人月缴存额'] = df['月供']/df['个人月缴存额']\n",
    "    df['归集余额+结转余额'] = df['个人账户上年结转余额']+df['个人账户当年归集余额']\n",
    "    df['公积金+结转余额'] = df['个人月缴存额']*24+df['个人账户上年结转余额']\n",
    "    df['公积金-归集余额'] = df['个人月缴存额']*24-df['个人账户当年归集余额']\n",
    "    df['归集余额+结转余额-个人账户余额'] = df['归集余额+结转余额']-df['个人账户余额']\n",
    "    df['个人月缴存额/贷款余额'] = df['个人月缴存额']/df['贷款余额']\n",
    "    df['个人账户余额/贷款余额'] = df['个人账户余额']/df['贷款余额']\n",
    "    df['个人月缴存额/贷款发放额'] = df['个人月缴存额']/df['贷款发放额']\n",
    "    df['贷款利率*贷款发放额'] = df['贷款利率']*df['贷款发放额']\n",
    "    df['贷款利率*贷款余额'] = df['贷款利率']*df['贷款余额']\n",
    "    df['个人缴存基数/个人账户余额'] = df['个人缴存基数']*df['个人账户余额']\n",
    "    df['个人缴存基数/个人账户上年结转余额'] = df['个人缴存基数']*df['个人账户上年结转余额']\n",
    "    df['个人缴存基数/贷款发放额'] = df['个人缴存基数']*df['贷款发放额']\n",
    "    df['个人缴存基数/贷款余额'] = df['个人缴存基数']*df['贷款余额']\n",
    "    df['贷款利率/个人缴存基数'] = df['贷款利率']/df['个人缴存基数']\n",
    "    df['公积金比例'] = df['个人月缴存额']/df['个人缴存基数']\n",
    "    df['贷款年限类别'] = df['贷款利率'].apply(loan_years)\n",
    "    df['第N房'] = df['贷款利率'].apply(num_house)\n",
    "    df['已还贷款'] = df['贷款发放额']-df['贷款余额']\n",
    "    df['贷款余额/公积金'] = df['贷款余额']/df['个人缴存基数']\n",
    "    df['已还贷款比例'] = df['已还贷款']/df['贷款发放额']\n",
    "    df['已还贷款年限'] = df['已还贷款']/df['月供']\n",
    "    df['贷款余额-个人账户余额'] = df['贷款余额']/df['个人账户余额']\n",
    "    \n",
    "    return df, genFeats2, genFeats3\n",
    "\n",
    "hand_gen_feats = ['贷款发放额_贷款余额', '贷款发放额_贷款余额_multi_贷款利率', '贷款发放额_multi_贷款利率',\n",
    "                  '贷款余额_multi_贷款利率', '贷款发放额_multi_贷款利率_ratio', '贷款余额_multi_贷款利率_ratio',\n",
    "                 '贷款余额_贷款发放额_ratio', '贷款发放额_贷款余额_ratio', '个人账户余额_diff_个人账户当年归集余额',\n",
    "                 '个人账户余额_diff_个人账户上年结转余额', '月供', '月供2', '还贷能力系数', '月供/个人缴存基数',\n",
    "                 '月供/个人月缴存额', '归集余额+结转余额-个人账户余额', '个人月缴存额/贷款余额', '个人账户余额/贷款余额',\n",
    "                 '个人月缴存额/贷款发放额', '贷款利率*贷款发放额', '贷款利率*贷款余额', '个人缴存基数/个人账户余额',\n",
    "                 '个人缴存基数/个人账户上年结转余额', '个人缴存基数/贷款发放额', '个人缴存基数/贷款余额', '贷款利率/个人缴存基数',\n",
    "                 '公积金比例', '贷款年限类别', '第N房', '已还贷款', '贷款余额/公积金', '已还贷款比例', '已还贷款年限',\n",
    "                 '贷款余额-个人账户余额']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_feat_engin(df, raw_cate_cols):\n",
    "    for f in tqdm(raw_cate_cols):\n",
    "        df[f].fillna('-1', inplace=True)\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[f])\n",
    "        df[f] = le.transform(df[f])\n",
    "        df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "        df = pd.concat([df,pd.get_dummies(df[f],prefix=f\"{f}\")],axis=1)\n",
    "        \n",
    "    cate_cols_combine = [[raw_cate_cols[i], raw_cate_cols[j]] for i in range(len(raw_cate_cols)) \\\n",
    "                         for j in range(i + 1, len(raw_cate_cols))]\n",
    "\n",
    "    for f1, f2 in tqdm(cate_cols_combine):\n",
    "        df['{}_{}_count'.format(f1, f2)] = df.groupby([f1, f2])['主键'].transform('count')\n",
    "        df['{}_in_{}_prop'.format(f1, f2)] = df['{}_{}_count'.format(f1, f2)] / df[f2 + '_count']\n",
    "        df['{}_in_{}_prop'.format(f2, f1)] = df['{}_{}_count'.format(f1, f2)] / df[f1 + '_count']\n",
    "\n",
    "    return df\n",
    "\n",
    "def cat_num_feat_engin(df, raw_cate_cols, raw_num_cols, hand_gen_feats, genFeats2, genFeats3):\n",
    "    for f1 in tqdm(raw_cate_cols):\n",
    "        g = df.groupby(f1)\n",
    "        for f2 in raw_num_cols + hand_gen_feats:\n",
    "            for stat in ['sum', 'mean', 'std', 'max', 'min', 'std']:\n",
    "                df['{}_{}_{}'.format(f1, f2, stat)] = g[f2].transform(stat)\n",
    "        for f3 in genFeats2 + genFeats3:\n",
    "            for stat in ['sum', 'mean']:\n",
    "                df['{}_{}_{}'.format(f1, f2, stat)] = g[f2].transform(stat)\n",
    "\n",
    "    return df\n",
    "\n",
    "def num_feat_engin(df, raw_num_cols, hand_gen_feats):\n",
    "    num_cols_gen_feats = raw_num_cols + hand_gen_feats\n",
    "    for f1 in tqdm(num_cols_gen_feats):\n",
    "        g = df.groupby(f1)\n",
    "        for f2 in num_cols_gen_feats:\n",
    "            if f1 != f2:\n",
    "                for stat in ['sum', 'mean', 'std', 'max', 'min', 'std']:\n",
    "                    df['{}_{}_{}'.format(f1, f2, stat)] = g[f2].transform(stat)\n",
    "\n",
    "    for i in tqdm(range(len(num_cols_gen_feats))):\n",
    "        for j in range(i + 1, len(num_cols_gen_feats)):\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_add'] = df[num_cols_gen_feats[i]] + df[num_cols_gen_feats[j]]\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_diff'] = df[num_cols_gen_feats[i]] - df[num_cols_gen_feats[j]]\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_multi'] = df[num_cols_gen_feats[i]] * df[num_cols_gen_feats[j]]\n",
    "            df[f'numsOf_{num_cols_gen_feats[i]}_{num_cols_gen_feats[j]}_div'] = df[num_cols_gen_feats[i]] / (df[num_cols_gen_feats[j]] + 0.0000000001)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标编码\n",
    "def kfold_mean(df_train, df_test, target, target_mean_list):\n",
    "    folds = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "    mean_of_target = df_train[target].mean()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in tqdm(\n",
    "            enumerate(folds.split(df_train, y=df_train[target]))):\n",
    "        tr_x = df_train.iloc[trn_idx, :]\n",
    "        vl_x = df_train.iloc[val_idx, :]\n",
    "\n",
    "        for col in target_mean_list:\n",
    "            df_train.loc[vl_x.index, f'{col}_target_enc'] = vl_x[col].map(\n",
    "                tr_x.groupby(col)[target].mean())\n",
    "\n",
    "    for col in target_mean_list:\n",
    "        df_train[f'{col}_target_enc'] = df_train[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "        \n",
    "        df_test[f'{col}_target_enc'] = df_test[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "\n",
    "    return pd.concat([df_train, df_test], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin(df, col, bins):\n",
    "    for i in range(len(bins)):\n",
    "        df[col+\"_genFeat\"+str(i)]=(df[col] > bins[i]).astype(int)\n",
    "       \n",
    "    return df, [col + f'_genFeat{i}' for i in range(len(bins))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 52.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 18.05it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 23.42it/s]\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\n",
      "100%|██████████| 42/42 [06:49<00:00,  9.75s/it]\n",
      " 10%|▉         | 4/42 [00:52<07:58, 12.60s/it]"
     ]
    }
   ],
   "source": [
    "df = kfold_mean(df[~df['是否逾期'].isna()], df[df['是否逾期'].isna()], '是否逾期', raw_cate_cols)\n",
    "df, genFeats2, genFeats3 = deal_table(df)\n",
    "df = cat_feat_engin(df, raw_cate_cols)\n",
    "df = cat_num_feat_engin(df, raw_cate_cols, raw_num_cols, hand_gen_feats, genFeats2, genFeats3)\n",
    "df = num_feat_engin(df, raw_num_cols, hand_gen_feats)\n",
    "train_data = df[df['是否逾期'].isna() == False].reset_index(drop=True)\n",
    "test_data = df[df['是否逾期'].isna() == True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feats = [f for f in train_data.columns if train_data[f].nunique() == 1 or train_data[f].nunique() == 0]\n",
    "cols = [col for col in train_data.columns if col not in ['主键', '是否逾期'] + drop_feats]\n",
    "len(drop_feats), drop_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_feat_cols = [col for col in list(train_data.columns) if col not in drop_cols]\n",
    "train_label = train_data['是否逾期']\n",
    "train_data = train_data[cols]\n",
    "test_data = test_data[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "params = {\n",
    "# 'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "    'metric': ['auc'],\n",
    "    'eval_metric': ['auc'],\n",
    "    'num_leaves': 31,\n",
    "#     'max_bin': 50,\n",
    "#         'max_depth': 6,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,  # 每次迭代中随机选择特征的比例\n",
    "    \"bagging_fraction\": 0.8,  # 每次迭代时用的数据比例\n",
    "    'min_child_samples': 25,\n",
    "    'n_jobs': -1,\n",
    "    'silent': True,  # 信息输出设置成1则没有信息输出\n",
    "    'seed': 1208,\n",
    "    'n_estimators':45000,\n",
    "    'scale_pos_weight':0.1,\n",
    "#         'lambda_l1':0.3,\n",
    "#         'lambda_l2':0.2,\n",
    "#     'min_split_gain':0.2,\n",
    "    'verbose' : -1\n",
    "    }  #设置出参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "oof_lgb = np.zeros(len(train_data))\n",
    "predictions_lgb = np.zeros(len(test_data))\n",
    "feat_importance_table = pd.DataFrame(columns=['feat', 'importance'])\n",
    "\n",
    "# for seed in [617, 1208, 916]:\n",
    "KF = StratifiedKFold(n_splits=n_folds, random_state=1208)\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(train_data.values, train_label.values)):\n",
    "#     trn_data = lgb.Dataset(train_data.iloc[trn_idx],label=train_label.iloc[trn_idx])    \n",
    "#     val_data = lgb.Dataset(train_data.iloc[val_idx],label=train_label.iloc[val_idx])\n",
    "    num_round = 45000\n",
    "    clf = LGBMClassifier(**params)\n",
    "\n",
    "    hist=clf.fit(\n",
    "\n",
    "        X = train_data.iloc[trn_idx],\n",
    "        y = train_label.iloc[trn_idx],\n",
    "#                     fobj=logloss,\n",
    "        eval_set = [(train_data.iloc[val_idx],train_label.iloc[val_idx])],\n",
    "        verbose=500,\n",
    "        early_stopping_rounds=1000,  \n",
    "#         eval_metric = tpr_weight_funtion\n",
    "#         categorical_feature=feature_list\n",
    "    )\n",
    "#         feat_importance_table['importance'+str(fold_)] = clf.feature_importances_\n",
    "    val_pred = clf.predict_proba(train_data.iloc[val_idx], num_iteration=clf.best_iteration_)[:,1]\n",
    "    oof_lgb[val_idx] = val_pred\n",
    "    predictions_lgb[:] += clf.predict_proba(test_data, num_iteration=clf.best_iteration_)[:,1]\n",
    "    print('--------------------------------'*2)\n",
    "    print(\"TPR: {}\".format(tpr_weight_funtion(train_label.iloc[val_idx], val_pred)))\n",
    "    print('--------------------------------'*2)\n",
    "# feat_importance_table['importance'] = feat_importance_table.mean(axis=1)\n",
    "# feat_importance_table['feat'] = clf.\n",
    "\n",
    "    print(\"AUC score: {}\".format(roc_auc_score(train_label, oof_lgb)))\n",
    "    print(\"TPR weight: {}\".format(tpr_weight_funtion(train_label,oof_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse：0.4793978962640551\n",
    "# l2: 0.4793978962640551\n",
    "# quantiled:0.47653246282190787\n",
    "# huber：0.47979688066739207\n",
    "# fair：0.4786361987667755\n",
    "# poisson：0.47279651795429817\n",
    "# tweedie：0.4684439608269858\n",
    "# binary_error：0.4763511062749365\n",
    "# cross_entropy：0.473449401523395\n",
    "# cross_entropy_lambda：0.4729778745012695\n",
    "# kullback_leibler：0.473449401523395\n",
    "# binary_logloss：0.473449401523395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.47435618425825177\n",
    "0.4803409503083061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_importance_table = pd.DataFrame(columns=['feat', 'importance'])\n",
    "# feat_importance_table['feat'] = gbm.feature_name()\n",
    "# feat_importance_table['importance'] = gbm.feature_importance()\n",
    "# feat_importance_table.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pre = gbm.predict(test_data, num_iteration=gbm.best_iteration)\n",
    "submit['label'] = predictions_lgb / 15\n",
    "submit.to_csv('../result//0114-02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
