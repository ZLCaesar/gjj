{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "drop_cols = ['主键', '婚姻状况', '职业', '职称', '职务', '学历', '单位月缴存额', '是否逾期']\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# drop_cols = ['主键', '是否逾期']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data'\n",
    "col_dict = {\n",
    "    'id': '主键',\n",
    "    'XINGBIE': '性别',\n",
    "    'CSNY': '出生年月',\n",
    "    'HYZK': '婚姻状况',\n",
    "    'ZHIYE': '职业',\n",
    "    'ZHICHEN': '职称',\n",
    "    'ZHIWU': '职务',\n",
    "    'XUELI': '学历',\n",
    "    'DWJJLX': '单位经济类型',\n",
    "    'DWSSHY': '单位所属行业',\n",
    "    'GRJCJS': '个人缴存基数',\n",
    "    'GRZHZT': '个人账户状态',\n",
    "    'GRZHYE': '个人账户余额',\n",
    "    'GRZHSNJZYE': '个人账户上年结转余额',\n",
    "    'GRZHDNGJYE': '个人账户当年归集余额', \n",
    "    'GRYJCE': '个人月缴存额',\n",
    "    'DWYJCE': '单位月缴存额',\n",
    "    'DKFFE': '贷款发放额',\n",
    "    'DKYE': '贷款余额',\n",
    "    'DKLL': '贷款利率',\n",
    "    'label': '是否逾期'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标编码\n",
    "def kfold_mean(df_train, df_test, target, target_mean_list):\n",
    "    folds = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "    mean_of_target = df_train[target].mean()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in tqdm(\n",
    "            enumerate(folds.split(df_train, y=df_train[target]))):\n",
    "        tr_x = df_train.iloc[trn_idx, :]\n",
    "        vl_x = df_train.iloc[val_idx, :]\n",
    "\n",
    "        for col in target_mean_list:\n",
    "            df_train.loc[vl_x.index, f'{col}_target_enc'] = vl_x[col].map(\n",
    "                tr_x.groupby(col)[target].mean())\n",
    "\n",
    "    for col in target_mean_list:\n",
    "        df_train[f'{col}_target_enc'] = df_train[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "        \n",
    "        df_test[f'{col}_target_enc'] = df_test[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "\n",
    "    return pd.concat([df_train, df_test], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(df,col):\n",
    "    df[col+\"_genFeat1\"]=(df[col] > 18).astype(int)\n",
    "    df[col+\"_genFeat2\"]=(df[col] > 25).astype(int)\n",
    "    df[col+\"_genFeat3\"]=(df[col] > 30).astype(int)\n",
    "    df[col+\"_genFeat4\"]=(df[col] > 35).astype(int)\n",
    "    df[col+\"_genFeat5\"]=(df[col] > 40).astype(int)\n",
    "    df[col+\"_genFeat6\"]=(df[col] > 45).astype(int)\n",
    "    return df, [col + f'_genFeat{i}' for i in range(1, 7)]\n",
    "\n",
    "def get_daikuanYE(df,col):\n",
    "    df[col + '_genFeat1'] = (df[col] > 100000).astype(int)\n",
    "    df[col + '_genFeat2'] = (df[col] > 120000).astype(int)\n",
    "    df[col + '_genFeat3'] = (df[col] > 140000).astype(int)\n",
    "    df[col + '_genFeat4'] = (df[col] > 180000).astype(int)\n",
    "    df[col + '_genFeat5'] = (df[col] > 220000).astype(int)\n",
    "    df[col + '_genFeat6'] = (df[col] > 260000).astype(int)\n",
    "    df[col + '_genFeat7'] = (df[col] > 300000).astype(int)\n",
    "    return df, [col + f'_genFeat{i}' for i in range(1, 8)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_pred, y):\n",
    "    y_true = y.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "#     grad = np.where(residual>0, -y_true/(np.exp(y_true*y_pred)+1), -y_true/(np.exp(y_true*y_pred)+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "#     hess = np.where(residual>0, np.exp(y_true*y_pred)/((np.exp(y_true*y_pred)+1)**2), np.exp(y_true*y_pred)/((np.exp(y_true*y_pred)+1)**2))#对预估里程低于实际里程的情况加大惩罚\n",
    "    grad = np.where(residual<0, -2*(residual)/(y_true+1), -5*2*(residual)/(y_true+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "    hess = np.where(residual<0, 2/(y_true+1), 5*2/(y_true+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_house_payments(p, i):\n",
    "    if i == 2.708 or i == 2.979:\n",
    "        n = 30*12\n",
    "    else:\n",
    "        n = 5*12\n",
    "    i = i/100\n",
    "    return p*i*(1+i)**n/((1+i)**n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = \"2021-1-01 00:00:00\"\n",
    "timestamp_assign = time.strptime(dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "timestamp_assign=time.mktime(timestamp_assign)\n",
    "def convert(x):\n",
    "    age = (datetime.datetime.fromtimestamp(timestamp_assign)-datetime.datetime.fromtimestamp(x)).days\n",
    "    return age//365+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(root+'/train.csv')\n",
    "test = pd.read_csv(root+'/test.csv')\n",
    "submit = pd.read_csv(root+'/submit.csv')\n",
    "train['CSNY'] = train['CSNY'].apply(convert)\n",
    "test['CSNY'] = test['CSNY'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "性别\n",
      "出生年月\n",
      "婚姻状况\n",
      "职业\n",
      "职称\n",
      "职务\n",
      "学历\n",
      "单位经济类型\n",
      "单位所属行业\n",
      "个人账户状态\n"
     ]
    }
   ],
   "source": [
    "train.columns=train.columns.map(col_dict)\n",
    "test.columns=test.columns.map(col_dict)\n",
    "for col in [f for f in train.select_dtypes('int64').columns if f not in ['是否逾期', '贷款发放额']]:\n",
    "    print(col)\n",
    "    train[col].fillna('-1', inplace=True)\n",
    "    test[col].fillna('-1', inplace=True)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train[[col]], test[[col]]], axis=0, ignore_index=True))\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首套\n",
    "#5年以上3.25： 2.708\n",
    "#1-5年 2.75： 2.292\n",
    "#二套\n",
    "#5年以上 3.575： 2.979\n",
    "#1-5年 3.025： 2.521\n",
    "rate_dict = {3.025: 2.521, 3.575: 2.979, 3.25: 2.708, 2.75: 2.292}\n",
    "\n",
    "def rate_func(x):\n",
    "    if x == 3.025:\n",
    "        return 2.521\n",
    "    if x == 3.575:\n",
    "        return 2.979\n",
    "    if x == 3.25:\n",
    "        return 2.708\n",
    "    if x == 2.75:\n",
    "        return 2.292\n",
    "    return x\n",
    "\n",
    "def loan_years(x):\n",
    "    if x == 2.708 or x == 2.979:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def num_house(x):\n",
    "    if x == 2.521 or x== 2.979:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ability_pay(gz, gjj, yg):\n",
    "    #还贷能力系数\n",
    "    return (gz+gjj)/yg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_feat(x, y):\n",
    "    feat_dic = {}\n",
    "    for i in range(len(x)):\n",
    "        pair = (x[i], y[i])\n",
    "        feat_dic[pair] = feat_dic.get(pair, 0) + 1\n",
    "\n",
    "    return feat_dic\n",
    "\n",
    "def HYJJLX(x, y, company_feat):\n",
    "    #行业+经济类型\n",
    "    if (x, y) in company_feat:\n",
    "        return company_feat[(x, y)]\n",
    "    return -1\n",
    "\n",
    "company_feat = combine_feat(list(train['单位经济类型']), list(train['单位所属行业']))\n",
    "company_feat = {k: v for k, v in company_feat.items() if v>50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['贷款利率'] = train['贷款利率'].apply(rate_func)\n",
    "test['贷款利率'] = test['贷款利率'].apply(rate_func)\n",
    "feature_list =  ['单位经济类型', '单位所属行业', '个人账户状态']\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "# data = kfold_mean(data[~data['是否逾期'].isna()], data[data['是否逾期'].isna()],\n",
    "#                   '是否逾期',\n",
    "#                   feature_list)\n",
    "\n",
    "# 频数统计\n",
    "\n",
    "for col in feature_list:\n",
    "    data[col + '_COUNT'] = data[col].map(data[col].value_counts())\n",
    "    col_idx = data[col].value_counts()\n",
    "    for idx in col_idx[col_idx < 5].index:\n",
    "        data[col] = data[col].replace(idx, -1)  \n",
    "        \n",
    "# 偏离值特征\n",
    "group_list = ['单位经济类型', '单位所属行业', '个人账户状态']\n",
    "num_feature_list = ['个人月缴存额', '贷款发放额', '贷款余额', '个人缴存基数',\n",
    "                    '个人账户上年结转余额', '个人账户当年归集余额']                   \n",
    "for group in group_list:\n",
    "    for feature in num_feature_list:\n",
    "        tmp = data.groupby(group)[feature].agg([sum, min, max, np.mean]).reset_index()\n",
    "        tmp = pd.merge(data, tmp, on=group, how='left')\n",
    "        data['{}-mean_gb_{}'.format(feature, group)] = data[feature] - tmp['mean']\n",
    "        data['{}-min_gb_{}'.format(feature, group)] = data[feature] - tmp['min']\n",
    "        data['{}-max_gb_{}'.format(feature, group)] = data[feature] - tmp['max']\n",
    "        data['{}/sum_gb_{}'.format(feature, group)] = data[feature] / tmp['sum']  \n",
    "train, test = data[~data['是否逾期'].isna()], data[data['是否逾期'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_feat_cols = [col for col in list(train.columns) if col not in drop_cols ]\n",
    "train_data = train[raw_feat_cols]\n",
    "test_data = test[raw_feat_cols]\n",
    "train_label = train['是否逾期']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data'\n",
    "col_dict = {\n",
    "    'id': '主键',\n",
    "    'XINGBIE': '性别',\n",
    "    'CSNY': '出生年月',\n",
    "    'HYZK': '婚姻状况',\n",
    "    'ZHIYE': '职业',\n",
    "    'ZHICHEN': '职称',\n",
    "    'ZHIWU': '职务',\n",
    "    'XUELI': '学历',\n",
    "    'DWJJLX': '单位经济类型',\n",
    "    'DWSSHY': '单位所属行业',\n",
    "    'GRJCJS': '个人缴存基数',\n",
    "    'GRZHZT': '个人账户状态',\n",
    "    'GRZHYE': '个人账户余额',\n",
    "    'GRZHSNJZYE': '个人账户上年结转余额',\n",
    "    'GRZHDNGJYE': '个人账户当年归集余额', \n",
    "    'GRYJCE': '个人月缴存额',\n",
    "    'DWYJCE': '单位月缴存额',\n",
    "    'DKFFE': '贷款发放额',\n",
    "    'DKYE': '贷款余额',\n",
    "    'DKLL': '贷款利率',\n",
    "    'label': '是否逾期'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_table(df):\n",
    "    df, genFeats1 = get_age(df, col = '出生年月')\n",
    "    df, genFeats2 = get_daikuanYE(df, col = '贷款余额')\n",
    "    df, genFeats3 = get_daikuanYE(df, col = '贷款发放额')\n",
    "    df['贷款发放额_贷款余额'] = df['贷款发放额'] + df['贷款余额']\n",
    "    df['贷款发放额_贷款余额_multi_贷款利率'] = (df['贷款发放额'] + df['贷款余额']) * df['贷款利率']\n",
    "    df['贷款发放额_multi_贷款利率'] = df['贷款发放额'] * df['贷款利率']\n",
    "    df['贷款余额_multi_贷款利率'] = df['贷款余额'] * df['贷款利率']\n",
    "\n",
    "    df['贷款发放额_multi_贷款利率_ratio'] = df['贷款发放额'] * df['贷款利率'] / df['贷款发放额_贷款余额_multi_贷款利率']\n",
    "    df['贷款余额_multi_贷款利率_ratio'] = df['贷款余额'] * df['贷款利率'] / df['贷款发放额_贷款余额_multi_贷款利率']\n",
    "    df['贷款余额_贷款发放额_ratio'] = df['贷款余额'] / df['贷款发放额_贷款余额']\n",
    "    df['贷款发放额_贷款余额_ratio'] = df['贷款发放额'] / df['贷款发放额_贷款余额']\n",
    "    df['个人账户余额_diff_个人账户当年归集余额'] = df['个人账户余额'] - df['个人账户当年归集余额']\n",
    "    df['个人账户余额_diff_个人账户上年结转余额'] = df['个人账户余额'] - df['个人账户上年结转余额']\n",
    "    df['行业+经济类型'] = df.apply(lambda row: HYJJLX(row['单位经济类型'], row['单位经济类型'], company_feat), axis=1)\n",
    "    df['月供'] = df.apply(lambda row: monthly_house_payments(row['贷款发放额'], row['贷款利率']), axis=1)\n",
    "    df['月供2'] = df.apply(lambda row: monthly_house_payments(row['贷款余额'], row['贷款利率']), axis=1)\n",
    "    df['还贷能力系数'] = df.apply(lambda row: ability_pay(row['个人缴存基数'], row['个人月缴存额'], row['月供']), axis=1)\n",
    "    df['月供/个人缴存基数'] = df['月供']/df['个人缴存基数']\n",
    "    df['月供/个人月缴存额'] = df['月供']/df['个人月缴存额']\n",
    "    df['归集余额+结转余额'] = df['个人账户上年结转余额']+df['个人账户当年归集余额']\n",
    "    df['公积金+结转余额'] = df['个人月缴存额']*24+df['个人账户上年结转余额']\n",
    "    df['公积金-归集余额'] = df['个人月缴存额']*24-df['个人账户当年归集余额']\n",
    "    df['归集余额+结转余额-个人账户余额'] = df['归集余额+结转余额']-df['个人账户余额']\n",
    "    df['个人月缴存额/贷款余额'] = df['个人月缴存额']/df['贷款余额']\n",
    "    df['个人账户余额/贷款余额'] = df['个人账户余额']/df['贷款余额']\n",
    "    df['个人月缴存额/贷款发放额'] = df['个人月缴存额']/df['贷款发放额']\n",
    "    df['贷款利率*贷款发放额'] = df['贷款利率']*df['贷款发放额']\n",
    "    df['贷款利率*贷款余额'] = df['贷款利率']*df['贷款余额']\n",
    "    df['个人缴存基数/个人账户余额'] = df['个人缴存基数']*df['个人账户余额']\n",
    "    df['个人缴存基数/个人账户上年结转余额'] = df['个人缴存基数']*df['个人账户上年结转余额']\n",
    "    df['个人缴存基数/贷款发放额'] = df['个人缴存基数']*df['贷款发放额']\n",
    "    df['个人缴存基数/贷款余额'] = df['个人缴存基数']*df['贷款余额']\n",
    "    df['贷款利率/个人缴存基数'] = df['贷款利率']/df['个人缴存基数']\n",
    "    df['公积金比例'] = df['个人月缴存额']/df['个人缴存基数']\n",
    "    df['贷款年限类别'] = df['贷款利率'].apply(loan_years)\n",
    "    df['第N房'] = df['贷款利率'].apply(num_house)\n",
    "    df['已还贷款'] = df['贷款发放额']-df['贷款余额']\n",
    "    df['贷款余额/公积金'] = df['贷款余额']/df['个人缴存基数']\n",
    "    df['已还贷款比例'] = df['已还贷款']/df['贷款发放额']\n",
    "    df['已还贷款年限'] = df['已还贷款']/df['月供']\n",
    "    df['贷款余额-个人账户余额'] = df['贷款余额']/df['个人账户余额']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_data = deal_table(train_data)\n",
    "test_data = deal_table(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "params = {\n",
    "# 'boosting_type': 'gbdt',\n",
    "#     'objective': 'binary',\n",
    "    'metric': ['auc'],\n",
    "    'eval_metric': ['auc'],\n",
    "    'num_leaves': 31,\n",
    "#     'max_bin': 50,\n",
    "#         'max_depth': 6,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,  # 每次迭代中随机选择特征的比例\n",
    "    \"bagging_fraction\": 0.8,  # 每次迭代时用的数据比例\n",
    "    'min_child_samples': 25,\n",
    "    'n_jobs': -1,\n",
    "    'silent': True,  # 信息输出设置成1则没有信息输出\n",
    "    'seed': 1208,\n",
    "    'n_estimators':45000,\n",
    "    'scale_pos_weight':0.1,\n",
    "#         'lambda_l1':0.3,\n",
    "#         'lambda_l2':0.2,\n",
    "#     'min_split_gain':0.2,\n",
    "    'verbose' : -1\n",
    "    }  #设置出参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.939598\n",
      "[1000]\tvalid_0's auc: 0.946424\n",
      "[1500]\tvalid_0's auc: 0.946754\n",
      "[2000]\tvalid_0's auc: 0.946752\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's auc: 0.94705\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4860507246376812\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.936434\n",
      "[1000]\tvalid_0's auc: 0.940579\n",
      "[1500]\tvalid_0's auc: 0.94033\n",
      "Early stopping, best iteration is:\n",
      "[816]\tvalid_0's auc: 0.941038\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4759057971014493\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.921696\n",
      "[1000]\tvalid_0's auc: 0.926733\n",
      "[1500]\tvalid_0's auc: 0.927297\n",
      "[2000]\tvalid_0's auc: 0.927048\n",
      "[2500]\tvalid_0's auc: 0.927271\n",
      "[3000]\tvalid_0's auc: 0.927678\n",
      "[3500]\tvalid_0's auc: 0.927666\n",
      "[4000]\tvalid_0's auc: 0.927521\n",
      "Early stopping, best iteration is:\n",
      "[3010]\tvalid_0's auc: 0.927738\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4780399274047187\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.926281\n",
      "[1000]\tvalid_0's auc: 0.930637\n",
      "[1500]\tvalid_0's auc: 0.930863\n",
      "[2000]\tvalid_0's auc: 0.931984\n",
      "[2500]\tvalid_0's auc: 0.932342\n",
      "[3000]\tvalid_0's auc: 0.932763\n",
      "[3500]\tvalid_0's auc: 0.933029\n",
      "[4000]\tvalid_0's auc: 0.93277\n",
      "Early stopping, best iteration is:\n",
      "[3330]\tvalid_0's auc: 0.933082\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.500907441016334\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.922466\n",
      "[1000]\tvalid_0's auc: 0.928643\n",
      "[1500]\tvalid_0's auc: 0.930521\n",
      "[2000]\tvalid_0's auc: 0.930821\n",
      "[2500]\tvalid_0's auc: 0.930624\n",
      "Early stopping, best iteration is:\n",
      "[1675]\tvalid_0's auc: 0.9309\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.45680580762250456\n",
      "----------------------------------------------------------------\n",
      "AUC score: 0.9329425268475912\n",
      "TPR weight: 0.48037722161770036\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.939598\n",
      "[1000]\tvalid_0's auc: 0.946424\n",
      "[1500]\tvalid_0's auc: 0.946754\n",
      "[2000]\tvalid_0's auc: 0.946752\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's auc: 0.94705\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4860507246376812\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.936434\n",
      "[1000]\tvalid_0's auc: 0.940579\n",
      "[1500]\tvalid_0's auc: 0.94033\n",
      "Early stopping, best iteration is:\n",
      "[816]\tvalid_0's auc: 0.941038\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4759057971014493\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.921696\n",
      "[1000]\tvalid_0's auc: 0.926733\n",
      "[1500]\tvalid_0's auc: 0.927297\n",
      "[2000]\tvalid_0's auc: 0.927048\n",
      "[2500]\tvalid_0's auc: 0.927271\n",
      "[3000]\tvalid_0's auc: 0.927678\n",
      "[3500]\tvalid_0's auc: 0.927666\n",
      "[4000]\tvalid_0's auc: 0.927521\n",
      "Early stopping, best iteration is:\n",
      "[3010]\tvalid_0's auc: 0.927738\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4780399274047187\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.926281\n",
      "[1000]\tvalid_0's auc: 0.930637\n",
      "[1500]\tvalid_0's auc: 0.930863\n",
      "[2000]\tvalid_0's auc: 0.931984\n",
      "[2500]\tvalid_0's auc: 0.932342\n",
      "[3000]\tvalid_0's auc: 0.932763\n",
      "[3500]\tvalid_0's auc: 0.933029\n",
      "[4000]\tvalid_0's auc: 0.93277\n",
      "Early stopping, best iteration is:\n",
      "[3330]\tvalid_0's auc: 0.933082\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.500907441016334\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.922466\n",
      "[1000]\tvalid_0's auc: 0.928643\n",
      "[1500]\tvalid_0's auc: 0.930521\n",
      "[2000]\tvalid_0's auc: 0.930821\n",
      "[2500]\tvalid_0's auc: 0.930624\n",
      "Early stopping, best iteration is:\n",
      "[1675]\tvalid_0's auc: 0.9309\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.45680580762250456\n",
      "----------------------------------------------------------------\n",
      "AUC score: 0.9329425268475912\n",
      "TPR weight: 0.48037722161770036\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.939598\n",
      "[1000]\tvalid_0's auc: 0.946424\n",
      "[1500]\tvalid_0's auc: 0.946754\n",
      "[2000]\tvalid_0's auc: 0.946752\n",
      "Early stopping, best iteration is:\n",
      "[1101]\tvalid_0's auc: 0.94705\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4860507246376812\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.936434\n",
      "[1000]\tvalid_0's auc: 0.940579\n",
      "[1500]\tvalid_0's auc: 0.94033\n",
      "Early stopping, best iteration is:\n",
      "[816]\tvalid_0's auc: 0.941038\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4759057971014493\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.921696\n",
      "[1000]\tvalid_0's auc: 0.926733\n",
      "[1500]\tvalid_0's auc: 0.927297\n",
      "[2000]\tvalid_0's auc: 0.927048\n",
      "[2500]\tvalid_0's auc: 0.927271\n",
      "[3000]\tvalid_0's auc: 0.927678\n",
      "[3500]\tvalid_0's auc: 0.927666\n",
      "[4000]\tvalid_0's auc: 0.927521\n",
      "Early stopping, best iteration is:\n",
      "[3010]\tvalid_0's auc: 0.927738\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.4780399274047187\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.926281\n",
      "[1000]\tvalid_0's auc: 0.930637\n",
      "[1500]\tvalid_0's auc: 0.930863\n",
      "[2000]\tvalid_0's auc: 0.931984\n",
      "[2500]\tvalid_0's auc: 0.932342\n",
      "[3000]\tvalid_0's auc: 0.932763\n",
      "[3500]\tvalid_0's auc: 0.933029\n",
      "[4000]\tvalid_0's auc: 0.93277\n",
      "Early stopping, best iteration is:\n",
      "[3330]\tvalid_0's auc: 0.933082\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.500907441016334\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\tvalid_0's auc: 0.922466\n",
      "[1000]\tvalid_0's auc: 0.928643\n",
      "[1500]\tvalid_0's auc: 0.930521\n",
      "[2000]\tvalid_0's auc: 0.930821\n",
      "[2500]\tvalid_0's auc: 0.930624\n",
      "Early stopping, best iteration is:\n",
      "[1675]\tvalid_0's auc: 0.9309\n",
      "----------------------------------------------------------------\n",
      "TPR: 0.45680580762250456\n",
      "----------------------------------------------------------------\n",
      "AUC score: 0.9329425268475912\n",
      "TPR weight: 0.48037722161770036\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "oof_lgb = np.zeros(len(train_data))\n",
    "predictions_lgb = np.zeros(len(test_data))\n",
    "feat_importance_table = pd.DataFrame(columns=['feat', 'importance'])\n",
    "\n",
    "for seed in [617, 1208, 916]:\n",
    "    KF = StratifiedKFold(n_splits=n_folds, random_state=seed)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(KF.split(train_data.values, train_label.values)):\n",
    "    #     trn_data = lgb.Dataset(train_data.iloc[trn_idx],label=train_label.iloc[trn_idx])    \n",
    "    #     val_data = lgb.Dataset(train_data.iloc[val_idx],label=train_label.iloc[val_idx])\n",
    "        num_round = 45000\n",
    "        clf = LGBMClassifier(**params)\n",
    "\n",
    "        hist=clf.fit(\n",
    "\n",
    "            X = train_data.iloc[trn_idx],\n",
    "            y = train_label.iloc[trn_idx],\n",
    "    #                     fobj=logloss,\n",
    "            eval_set = [(train_data.iloc[val_idx],train_label.iloc[val_idx])],\n",
    "            verbose=500,\n",
    "            early_stopping_rounds=1000,  \n",
    "    #         eval_metric = tpr_weight_funtion\n",
    "    #         categorical_feature=feature_list\n",
    "        )\n",
    "#         feat_importance_table['importance'+str(fold_)] = clf.feature_importances_\n",
    "        val_pred = clf.predict_proba(train_data.iloc[val_idx], num_iteration=clf.best_iteration_)[:,1]\n",
    "        oof_lgb[val_idx] = val_pred\n",
    "        predictions_lgb[:] += clf.predict_proba(test_data, num_iteration=clf.best_iteration_)[:,1]\n",
    "        print('--------------------------------'*2)\n",
    "        print(\"TPR: {}\".format(tpr_weight_funtion(train_label.iloc[val_idx], val_pred)))\n",
    "        print('--------------------------------'*2)\n",
    "# feat_importance_table['importance'] = feat_importance_table.mean(axis=1)\n",
    "# feat_importance_table['feat'] = clf.\n",
    "\n",
    "    print(\"AUC score: {}\".format(roc_auc_score(train_label, oof_lgb)))\n",
    "    print(\"TPR weight: {}\".format(tpr_weight_funtion(train_label,oof_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse：0.4793978962640551\n",
    "# l2: 0.4793978962640551\n",
    "# quantiled:0.47653246282190787\n",
    "# huber：0.47979688066739207\n",
    "# fair：0.4786361987667755\n",
    "# poisson：0.47279651795429817\n",
    "# tweedie：0.4684439608269858\n",
    "# binary_error：0.4763511062749365\n",
    "# cross_entropy：0.473449401523395\n",
    "# cross_entropy_lambda：0.4729778745012695\n",
    "# kullback_leibler：0.473449401523395\n",
    "# binary_logloss：0.473449401523395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4803409503083061"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.47435618425825177\n",
    "0.4803409503083061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_importance_table = pd.DataFrame(columns=['feat', 'importance'])\n",
    "# feat_importance_table['feat'] = gbm.feature_name()\n",
    "# feat_importance_table['importance'] = gbm.feature_importance()\n",
    "# feat_importance_table.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pre = gbm.predict(test_data, num_iteration=gbm.best_iteration)\n",
    "submit['label'] = predictions_lgb / 15\n",
    "submit.to_csv('../result//0114-02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.002371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     label\n",
       "0  test_0  0.000225\n",
       "1  test_1  0.001134\n",
       "2  test_2  0.002371\n",
       "3  test_3  0.000598\n",
       "4  test_4  0.001753"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
