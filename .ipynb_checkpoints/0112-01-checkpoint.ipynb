{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "drop_cols = ['主键', '婚姻状况', '职业', '职称', '职务', '学历', '单位月缴存额', '是否逾期']\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# drop_cols = ['主键', '是否逾期']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data'\n",
    "col_dict = {\n",
    "    'id': '主键',\n",
    "    'XINGBIE': '性别',\n",
    "    'CSNY': '出生年月',\n",
    "    'HYZK': '婚姻状况',\n",
    "    'ZHIYE': '职业',\n",
    "    'ZHICHEN': '职称',\n",
    "    'ZHIWU': '职务',\n",
    "    'XUELI': '学历',\n",
    "    'DWJJLX': '单位经济类型',\n",
    "    'DWSSHY': '单位所属行业',\n",
    "    'GRJCJS': '个人缴存基数',\n",
    "    'GRZHZT': '个人账户状态',\n",
    "    'GRZHYE': '个人账户余额',\n",
    "    'GRZHSNJZYE': '个人账户上年结转余额',\n",
    "    'GRZHDNGJYE': '个人账户当年归集余额', \n",
    "    'GRYJCE': '个人月缴存额',\n",
    "    'DWYJCE': '单位月缴存额',\n",
    "    'DKFFE': '贷款发放额',\n",
    "    'DKYE': '贷款余额',\n",
    "    'DKLL': '贷款利率',\n",
    "    'label': '是否逾期'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标编码\n",
    "def kfold_mean(df_train, df_test, target, target_mean_list):\n",
    "    folds = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "    mean_of_target = df_train[target].mean()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in tqdm(\n",
    "            enumerate(folds.split(df_train, y=df_train[target]))):\n",
    "        tr_x = df_train.iloc[trn_idx, :]\n",
    "        vl_x = df_train.iloc[val_idx, :]\n",
    "\n",
    "        for col in target_mean_list:\n",
    "            df_train.loc[vl_x.index, f'{col}_target_enc'] = vl_x[col].map(\n",
    "                tr_x.groupby(col)[target].mean())\n",
    "\n",
    "    for col in target_mean_list:\n",
    "        df_train[f'{col}_target_enc'] = df_train[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "        \n",
    "        df_test[f'{col}_target_enc'] = df_test[col].map(\n",
    "            df_train.groupby(col)[f'{col}_target_enc'].mean())\n",
    "\n",
    "    return pd.concat([df_train, df_test], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_predict,y_true):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "\n",
    "    return 'tpr', 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_pred, y):\n",
    "    y_true = y.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "#     grad = np.where(residual>0, -y_true/(np.exp(y_true*y_pred)+1), -y_true/(np.exp(y_true*y_pred)+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "#     hess = np.where(residual>0, np.exp(y_true*y_pred)/((np.exp(y_true*y_pred)+1)**2), np.exp(y_true*y_pred)/((np.exp(y_true*y_pred)+1)**2))#对预估里程低于实际里程的情况加大惩罚\n",
    "    grad = np.where(residual>0, -2*(residual)/(y_true+1), -5*2*(residual)/(y_true+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "    hess = np.where(residual>0, 2/(y_true+1), 5*2/(y_true+1))#对预估里程低于实际里程的情况加大惩罚\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_house_payments(p, i):\n",
    "    if i == 2.708 or i == 2.979:\n",
    "        n = 30*12\n",
    "    else:\n",
    "        n = 5*12\n",
    "    i = i/100\n",
    "    return p*i*(1+i)**n/((1+i)**n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = \"2021-1-01 00:00:00\"\n",
    "timestamp_assign = time.strptime(dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "timestamp_assign=time.mktime(timestamp_assign)\n",
    "def convert(x):\n",
    "    age = (datetime.datetime.fromtimestamp(timestamp_assign)-datetime.datetime.fromtimestamp(x)).days\n",
    "    return age//365+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(root+'/train.csv')\n",
    "test = pd.read_csv(root+'/test.csv')\n",
    "submit = pd.read_csv(root+'/submit.csv')\n",
    "train['CSNY'] = train['CSNY'].apply(convert)\n",
    "test['CSNY'] = test['CSNY'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "性别\n",
      "出生年月\n",
      "婚姻状况\n",
      "职业\n",
      "职称\n",
      "职务\n",
      "学历\n",
      "单位经济类型\n",
      "单位所属行业\n",
      "个人账户状态\n"
     ]
    }
   ],
   "source": [
    "train.columns=train.columns.map(col_dict)\n",
    "test.columns=test.columns.map(col_dict)\n",
    "for col in [f for f in train.select_dtypes('int64').columns if f not in ['是否逾期', '贷款发放额']]:\n",
    "    print(col)\n",
    "    train[col].fillna('-1', inplace=True)\n",
    "    test[col].fillna('-1', inplace=True)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train[[col]], test[[col]]], axis=0, ignore_index=True))\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首套\n",
    "#5年以上3.25： 2.708\n",
    "#1-5年 2.75： 2.292\n",
    "#二套\n",
    "#5年以上 3.575： 2.979\n",
    "#1-5年 3.025： 2.521\n",
    "rate_dict = {3.025: 2.521, 3.575: 2.979, 3.25: 2.708, 2.75: 2.292}\n",
    "\n",
    "def rate_func(x):\n",
    "    if x == 3.025:\n",
    "        return 2.521\n",
    "    if x == 3.575:\n",
    "        return 2.979\n",
    "    if x == 3.25:\n",
    "        return 2.708\n",
    "    if x == 2.75:\n",
    "        return 2.292\n",
    "    return x\n",
    "\n",
    "def loan_years(x):\n",
    "    if x == 2.708 or x == 2.979:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def num_house(x):\n",
    "    if x == 2.521 or x== 2.979:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ability_pay(gz, gjj, yg):\n",
    "    #还贷能力系数\n",
    "    return (gz+gjj)/yg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_feat(x, y):\n",
    "    feat_dic = {}\n",
    "    for i in range(len(x)):\n",
    "        pair = (x[i], y[i])\n",
    "        feat_dic[pair] = feat_dic.get(pair, 0) + 1\n",
    "\n",
    "    return feat_dic\n",
    "\n",
    "def HYJJLX(x, y, company_feat):\n",
    "    #行业+经济类型\n",
    "    if (x, y) in company_feat:\n",
    "        return company_feat[(x, y)]\n",
    "    return -1\n",
    "\n",
    "company_feat = combine_feat(list(train['单位经济类型']), list(train['单位所属行业']))\n",
    "company_feat = {k: v for k, v in company_feat.items() if v>50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['贷款利率'] = train['贷款利率'].apply(rate_func)\n",
    "test['贷款利率'] = test['贷款利率'].apply(rate_func)\n",
    "feature_list =  ['单位经济类型', '单位所属行业', '个人账户状态']\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "# data = kfold_mean(data[~data['是否逾期'].isna()], data[data['是否逾期'].isna()],\n",
    "#                   '是否逾期',\n",
    "#                   feature_list)\n",
    "\n",
    "# 频数统计\n",
    "\n",
    "for col in feature_list:\n",
    "    data[col + '_COUNT'] = data[col].map(data[col].value_counts())\n",
    "    col_idx = data[col].value_counts()\n",
    "    for idx in col_idx[col_idx < 5].index:\n",
    "        data[col] = data[col].replace(idx, -1)  \n",
    "        \n",
    "# 偏离值特征\n",
    "group_list = ['单位经济类型', '单位所属行业', '个人账户状态']\n",
    "num_feature_list = ['个人月缴存额', '贷款发放额', '贷款余额', '个人缴存基数',\n",
    "                    '个人账户上年结转余额', '个人账户当年归集余额']                   \n",
    "for group in group_list:\n",
    "    for feature in num_feature_list:\n",
    "        tmp = data.groupby(group)[feature].agg([sum, min, max, np.mean]).reset_index()\n",
    "        tmp = pd.merge(data, tmp, on=group, how='left')\n",
    "        data['{}-mean_gb_{}'.format(feature, group)] = data[feature] - tmp['mean']\n",
    "        data['{}-min_gb_{}'.format(feature, group)] = data[feature] - tmp['min']\n",
    "        data['{}-max_gb_{}'.format(feature, group)] = data[feature] - tmp['max']\n",
    "        data['{}/sum_gb_{}'.format(feature, group)] = data[feature] / tmp['sum']  \n",
    "train, test = data[~data['是否逾期'].isna()], data[data['是否逾期'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_feat_cols = [col for col in list(train.columns) if col not in drop_cols ]\n",
    "train_data = train[raw_feat_cols]\n",
    "test_data = test[raw_feat_cols]\n",
    "train_label = train['是否逾期']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['行业+经济类型'] = train_data.apply(lambda row: HYJJLX(row['单位经济类型'], row['单位经济类型'], company_feat), axis=1)\n",
    "train_data['月供'] = train_data.apply(lambda row: monthly_house_payments(row['贷款发放额'], row['贷款利率']), axis=1)\n",
    "train_data['月供2'] = train_data.apply(lambda row: monthly_house_payments(row['贷款余额'], row['贷款利率']), axis=1)\n",
    "train_data['还贷能力系数'] = train_data.apply(lambda row: ability_pay(row['个人缴存基数'], row['个人月缴存额'], row['月供']), axis=1)\n",
    "train_data['月供/个人缴存基数'] = train_data['月供']/train_data['个人缴存基数']\n",
    "train_data['月供/个人月缴存额'] = train_data['月供']/train_data['个人月缴存额']\n",
    "train_data['归集余额+结转余额'] = train_data['个人账户上年结转余额']+train_data['个人账户当年归集余额']\n",
    "train_data['归集余额+结转余额-个人账户余额'] = train_data['归集余额+结转余额']-train_data['个人账户余额']\n",
    "train_data['个人月缴存额/贷款余额'] = train_data['个人月缴存额']/train_data['贷款余额']\n",
    "train_data['个人账户余额/贷款余额'] = train_data['个人账户余额']/train_data['贷款余额']\n",
    "train_data['个人月缴存额/贷款发放额'] = train_data['个人月缴存额']/train_data['贷款发放额']\n",
    "train_data['贷款利率*贷款发放额'] = train_data['贷款利率']*train_data['贷款发放额']\n",
    "train_data['贷款利率*贷款余额'] = train_data['贷款利率']*train_data['贷款余额']\n",
    "train_data['个人缴存基数/个人账户余额'] = train_data['个人缴存基数']*train_data['个人账户余额']\n",
    "train_data['个人缴存基数/个人账户上年结转余额'] = train_data['个人缴存基数']*train_data['个人账户上年结转余额']\n",
    "train_data['个人缴存基数/贷款发放额'] = train_data['个人缴存基数']*train_data['贷款发放额']\n",
    "train_data['个人缴存基数/贷款余额'] = train_data['个人缴存基数']*train_data['贷款余额']\n",
    "train_data['贷款利率/个人缴存基数'] = train_data['贷款利率']/train_data['个人缴存基数']\n",
    "train_data['公积金比例'] = train_data['个人月缴存额']/train_data['个人缴存基数']\n",
    "train_data['贷款年限类别'] = train_data['贷款利率'].apply(loan_years)\n",
    "train_data['第N房'] = train_data['贷款利率'].apply(num_house)\n",
    "train_data['已还贷款'] = train_data['贷款发放额']-train_data['贷款余额']\n",
    "train_data['贷款余额/公积金'] = train_data['贷款余额']/train_data['个人缴存基数']\n",
    "train_data['已还贷款比例'] = train_data['已还贷款']/train_data['贷款发放额']\n",
    "\n",
    "test_data['行业+经济类型'] = test_data.apply(lambda row: HYJJLX(row['单位经济类型'], row['单位经济类型'], company_feat), axis=1)\n",
    "test_data['月供'] = test_data.apply(lambda row: monthly_house_payments(row['贷款发放额'], row['贷款利率']), axis=1)\n",
    "test_data['月供2'] = test_data.apply(lambda row: monthly_house_payments(row['贷款余额'], row['贷款利率']), axis=1)\n",
    "test_data['还贷能力系数'] = test_data.apply(lambda row: ability_pay(row['个人缴存基数'], row['个人月缴存额'], row['月供']), axis=1)\n",
    "test_data['月供/个人缴存基数'] = test_data['月供']/test_data['个人缴存基数']\n",
    "test_data['月供/个人月缴存额'] = test_data['月供']/test_data['个人月缴存额']\n",
    "test_data['归集余额+结转余额'] = test_data['个人账户上年结转余额']+test_data['个人账户当年归集余额']\n",
    "test_data['归集余额+结转余额-个人账户余额'] = test_data['归集余额+结转余额']-test_data['个人账户余额']\n",
    "test_data['个人月缴存额/贷款余额'] = test_data['个人月缴存额']/test_data['贷款余额']\n",
    "test_data['个人账户余额/贷款余额'] = test_data['个人账户余额']/test_data['贷款余额']\n",
    "test_data['个人月缴存额/贷款发放额'] = test_data['个人月缴存额']/test_data['贷款发放额']\n",
    "test_data['贷款利率*贷款发放额'] = test_data['贷款利率']*test_data['贷款发放额']\n",
    "test_data['贷款利率*贷款余额'] = test_data['贷款利率']*test_data['贷款余额']\n",
    "test_data['个人缴存基数/个人账户余额'] = test_data['个人缴存基数']*test_data['个人账户余额']\n",
    "test_data['个人缴存基数/个人账户上年结转余额'] = test_data['个人缴存基数']*test_data['个人账户上年结转余额']\n",
    "test_data['个人缴存基数/贷款发放额'] = test_data['个人缴存基数']*test_data['贷款发放额']\n",
    "test_data['个人缴存基数/贷款余额'] = test_data['个人缴存基数']*test_data['贷款余额']\n",
    "test_data['贷款利率/个人缴存基数'] = test_data['贷款利率']/test_data['个人缴存基数']\n",
    "test_data['公积金比例'] = test_data['个人月缴存额']/test_data['个人缴存基数']\n",
    "test_data['贷款年限类别'] = test_data['贷款利率'].apply(loan_years)\n",
    "test_data['第N房'] = test_data['贷款利率'].apply(num_house)\n",
    "test_data['已还贷款'] = test_data['贷款发放额']-test_data['贷款余额']\n",
    "test_data['贷款余额/公积金'] = test_data['贷款余额']/test_data['个人缴存基数']\n",
    "test_data['已还贷款比例'] = test_data['已还贷款']/test_data['贷款发放额']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': ['binary_logloss', 'auc'],\n",
    "        'num_leaves': 31,\n",
    "        'max_bin': 50,\n",
    "#         'max_depth': 6,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"colsample_bytree\": 0.8,  # 每次迭代中随机选择特征的比例\n",
    "        \"bagging_fraction\": 0.8,  # 每次迭代时用的数据比例\n",
    "        'min_child_samples': 25,\n",
    "        'n_jobs': -1,\n",
    "        'silent': True,  # 信息输出设置成1则没有信息输出\n",
    "        'seed': 1208,\n",
    "        'scale_pos_weight':0.1,\n",
    "#         'lambda_l1':0.3,\n",
    "#         'lambda_l2':0.2,\n",
    "#     'min_split_gain':0.2,\n",
    "        'verbose' : -1\n",
    "    }  #设置出参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def tpr_weight_function(y_true, y_predict):\n",
    "#     d = pd.DataFrame()\n",
    "#     d['prob'] = list(y_predict)\n",
    "#     d['y'] = list(y_true)\n",
    "#     d = d.sort_values(['prob'], ascending=[0])\n",
    "#     y = d.y\n",
    "#     PosAll = pd.Series(y).value_counts()[1]\n",
    "#     NegAll = pd.Series(y).value_counts()[0]\n",
    "#     pCumsum = d['y'].cumsum()\n",
    "#     nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "#     pCumsumPer = pCumsum / PosAll\n",
    "#     nCumsumPer = nCumsum / NegAll\n",
    "#     TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "#     TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "#     TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "#     return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3\n",
    "\n",
    "\n",
    "# def eval_error(pred, train_set):\n",
    "#     labels = train_set.get_label()\n",
    "#     score = tpr_weight_function(labels, pred)\n",
    "#     return 'TPR', score, True\n",
    "\n",
    "# #%%\n",
    "\n",
    "# def bayes_parameter_opt_lgb(X, y, init_round, opt_round, n_folds, random_seed, n_estimators, learning_rate, output_process=False):\n",
    "#     # prepare data\n",
    "#     train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "#     # parameters\n",
    "#     def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth,  max_bin, learning_rate, min_split_gain, min_child_weight):\n",
    "#         params = {'application':'binary','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':200, 'eval_metric':'tprw','is_unbalance':True}\n",
    "#         params[\"num_leaves\"] = int(round(num_leaves))\n",
    "#         params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "#         params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "#         params['max_depth'] = int(round(max_depth))\n",
    "# #         params['lambda_l1'] = max(lambda_l1, 0)\n",
    "# #         params['lambda_l2'] = max(lambda_l2, 0)\n",
    "#         params['max_bin'] = int(round(max_bin))\n",
    "#         params['learning_rate'] = learning_rate\n",
    "#         params['min_split_gain'] = min_split_gain\n",
    "#         params['min_child_weight'] = min_child_weight\n",
    "#         cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =100,feval=eval_error)\n",
    "#         return max(cv_result['TPR-mean'])\n",
    "#     # range \n",
    "#     lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (10, 100),\n",
    "#                                             'feature_fraction': (0.1, 1),\n",
    "#                                             'bagging_fraction': (0.1, 1),\n",
    "#                                             'max_depth': (4, 8),\n",
    "# #                                             'lambda_l1': (0, 10),\n",
    "# #                                             'lambda_l2': (0, 10),\n",
    "#                                             'max_bin': (10, 100),\n",
    "#                                             'learning_rate': (0.001,0.1),\n",
    "#                                             'min_split_gain': (0.01, 0.6),\n",
    "#                                             'min_child_weight': (0.1, 30)},random_state=random_seed)#\n",
    "#     # optimize\n",
    "#     lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "#     # output optimization process\n",
    "#     if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "#     # return best parameters\n",
    "# #     return lgbBO.res['max']['max_params']\n",
    "#     return lgbBO\n",
    "\n",
    "# #%%\n",
    "# opt_params = bayes_parameter_opt_lgb(train_data,train_label, init_round=5, opt_round=10, n_folds=5, random_seed=13, n_estimators=10000, learning_rate=0.02)\n",
    "# print(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.944232\ttraining's binary_logloss: 0.165283\tvalid_1's auc: 0.935969\tvalid_1's binary_logloss: 0.176567\n",
      "[1000]\ttraining's auc: 0.963764\ttraining's binary_logloss: 0.144314\tvalid_1's auc: 0.939439\tvalid_1's binary_logloss: 0.176819\n",
      "[1500]\ttraining's auc: 0.973066\ttraining's binary_logloss: 0.131698\tvalid_1's auc: 0.938923\tvalid_1's binary_logloss: 0.176386\n",
      "Early stopping, best iteration is:\n",
      "[630]\ttraining's auc: 0.950589\ttraining's binary_logloss: 0.156623\tvalid_1's auc: 0.936983\tvalid_1's binary_logloss: 0.17363\n",
      "----------------------------------------------------------------\n",
      "TPR: ('tpr', 0.4503623188405797, True)\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.944204\ttraining's binary_logloss: 0.164355\tvalid_1's auc: 0.935833\tvalid_1's binary_logloss: 0.174682\n",
      "[1000]\ttraining's auc: 0.962712\ttraining's binary_logloss: 0.144422\tvalid_1's auc: 0.940197\tvalid_1's binary_logloss: 0.171838\n",
      "[1500]\ttraining's auc: 0.972724\ttraining's binary_logloss: 0.133795\tvalid_1's auc: 0.940593\tvalid_1's binary_logloss: 0.167872\n",
      "[2000]\ttraining's auc: 0.979095\ttraining's binary_logloss: 0.123455\tvalid_1's auc: 0.939309\tvalid_1's binary_logloss: 0.172072\n",
      "Early stopping, best iteration is:\n",
      "[1375]\ttraining's auc: 0.970904\ttraining's binary_logloss: 0.13558\tvalid_1's auc: 0.941032\tvalid_1's binary_logloss: 0.16857\n",
      "----------------------------------------------------------------\n",
      "TPR: ('tpr', 0.45307971014492754, True)\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.948155\ttraining's binary_logloss: 0.160405\tvalid_1's auc: 0.919291\tvalid_1's binary_logloss: 0.197091\n",
      "[1000]\ttraining's auc: 0.966298\ttraining's binary_logloss: 0.141649\tvalid_1's auc: 0.923795\tvalid_1's binary_logloss: 0.2012\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's auc: 0.94423\ttraining's binary_logloss: 0.163603\tvalid_1's auc: 0.916359\tvalid_1's binary_logloss: 0.190719\n",
      "----------------------------------------------------------------\n",
      "TPR: ('tpr', 0.4143375680580762, True)\n",
      "----------------------------------------------------------------\n",
      "Training until validation scores don't improve for 1000 rounds.\n"
     ]
    }
   ],
   "source": [
    "KF = StratifiedKFold(n_splits=5, random_state=2020)\n",
    "oof_lgb = np.zeros(len(train_data))\n",
    "predictions_lgb = np.zeros((len(test_data)))\n",
    "feat_importance_table = pd.DataFrame(columns=['feat', 'importance'])\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(train_data.values, train_label.values)):\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx],label=train_label.iloc[trn_idx])    \n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx],label=train_label.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(\n",
    "        params,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    fobj=logloss,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds=1000,  \n",
    "#         categorical_feature=feature_list\n",
    "    )\n",
    "    feat_importance_table['importance'+str(fold_)] = clf.feature_importance()\n",
    "    val_pred = clf.predict(train_data.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    oof_lgb[val_idx] = val_pred\n",
    "    predictions_lgb[:] += clf.predict(test_data, num_iteration=clf.best_iteration) \n",
    "    print('--------------------------------'*2)\n",
    "    print(\"TPR: {}\".format(tpr_weight_funtion(val_pred, train_label.iloc[val_idx])))\n",
    "    print('--------------------------------'*2)\n",
    "feat_importance_table['importance'] = feat_importance_table.mean(axis=1)\n",
    "feat_importance_table['feat'] = clf.feature_name()\n",
    "\n",
    "print(\"AUC score: {}\".format(roc_auc_score(train_label, oof_lgb)))\n",
    "print(\"TPR weight: {}\".format(tpr_weight_funtion(oof_lgb, train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.47435618425825177\n",
    "0.4803409503083061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# feat_importance_table = pd.DataFrame(columns=['feat', 'importance'])\n",
    "# feat_importance_table['feat'] = gbm.feature_name()\n",
    "# feat_importance_table['importance'] = gbm.feature_importance()\n",
    "feat_importance_table.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pre = gbm.predict(test_data, num_iteration=gbm.best_iteration)\n",
    "submit['label'] = predictions_lgb / 5\n",
    "submit.to_csv('../0111-03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
